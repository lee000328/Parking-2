import argparse
from ultralytics import YOLO
import cv2
import torch
import numpy as np
from pathlib import Path
from torchvision.ops import nms
from glob import glob


from glob import glob

def load_models(weight_glob_pattern):
    if isinstance(weight_glob_pattern, list):
        weight_glob_pattern = weight_glob_pattern[0]  # ë¦¬ìŠ¤íŠ¸ë©´ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
    weight_paths = sorted(glob(weight_glob_pattern))
    if not weight_paths:
        raise FileNotFoundError(f"No .pt files found matching: {weight_glob_pattern}")
    return [YOLO(w) for w in weight_paths]


def run_inference(models, image_path):
    """ëª¨ë“  ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ì¶”ë¡ í•˜ê³  ê²°ê³¼ ë³‘í•©"""
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    all_boxes, all_scores, all_classes = [], [], []

    for model in models:
        results = model.predict(source=img_rgb, conf=0.25, iou=0.45, verbose=False)
        result = results[0]
        all_boxes.append(result.boxes.xyxy.cpu().numpy())
        all_scores.append(result.boxes.conf.cpu().numpy())
        all_classes.append(result.boxes.cls.cpu().numpy())

    boxes = np.vstack(all_boxes)
    scores = np.hstack(all_scores)
    classes = np.hstack(all_classes)

    keep = nms(torch.tensor(boxes), torch.tensor(scores), iou_threshold=0.5)

    return img, boxes[keep.numpy()], scores[keep.numpy()], classes[keep.numpy()], models[0].names

def visualize(img, boxes, scores, classes, names, save_path='ensemble_result.jpg'):
    """ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™” ë° ì €ì¥"""
    for box, score, cls in zip(boxes, scores, classes):
        x1, y1, x2, y2 = map(int, box)
        label = f"{names[int(cls)]} {score:.2f}"
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    cv2.imwrite(save_path, img)
    cv2.imshow('Result', img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def classify(classes, names):
    """ì£¼ì°¨ì¥ ìœ í˜• ë¶„ë¥˜"""
    detected = [names[int(cls)] for cls in classes]
    print(f"ê°ì§€ëœ í´ë˜ìŠ¤: {detected}")
    if any(cls in detected for cls in ['pillar', 'rebar', 'wall']):
        print("ğŸ…¿ï¸ ì§€í•˜ í˜¹ì€ ê±´ë¬¼í˜• ì£¼ì°¨ì¥ì…ë‹ˆë‹¤.")
    else:
        print("ğŸ…¿ï¸ ì¼ë°˜ ì£¼ì°¨ì¥ì…ë‹ˆë‹¤.")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', type=str, choices=['infer', 'classify'], default='classify',
                        help="ì‘ì—… ëª¨ë“œ ì„ íƒ: 'infer'(ì´ë¯¸ì§€ ì‹œê°í™”) or 'classify'(ì¢…ë¥˜ ë¶„ë¥˜)")
    parser.add_argument('--weights', nargs='+', required=True, help="YOLO ê°€ì¤‘ì¹˜ ê²½ë¡œë“¤")
    parser.add_argument('--image', type=str, required=True, help="ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ")
    args = parser.parse_args()

    models = load_models(args.weights)
    img, boxes, scores, classes, names = run_inference(models, args.image)

    if args.mode == 'infer':
        visualize(img, boxes, scores, classes, names)
    elif args.mode == 'classify':
        classify(classes, names)

if __name__ == "__main__":
    main()
